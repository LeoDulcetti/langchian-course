üß† Resumen del c√≥digo ‚Äì Agente ReAct completo (LangChain cl√°sico)
Este programa demuestra c√≥mo construir un agente ReAct (Reason + Act) de forma manual, usando las librer√≠as de LangChain Classic y OpenAI, ejecutando un ciclo completo de pensamiento ‚Üí acci√≥n ‚Üí observaci√≥n ‚Üí respuesta final.
El objetivo es que el modelo razone, decida una acci√≥n, ejecute una herramienta real (a trav√©s de Python) y luego use el resultado para concluir su respuesta final.
‚öôÔ∏è 1) Concepto general
En un agente ReAct, el LLM (modelo) no ejecuta herramientas por s√≠ mismo:
solo razona en lenguaje natural y decide qu√© acci√≥n tomar.
El entorno (en este caso, tu c√≥digo en Python) interpreta esas instrucciones, ejecuta la herramienta correspondiente y devuelve la observaci√≥n al modelo.
El flujo general del agente es:
Question ‚Üí Thought ‚Üí Action ‚Üí Action Input ‚Üí Observation ‚Üí Thought ‚Üí Final Answer
Cada paso posterior se construye sobre un ‚Äúscratchpad‚Äù, un historial de pensamientos y observaciones que el modelo utiliza para razonar con memoria de contexto.
üß© 2) Componentes principales
‚úÖ get_text_length (herramienta)
Una funci√≥n decorada con @tool que recibe un texto y devuelve su longitud en caracteres.
Esta funci√≥n es el ‚Äúacto‚Äù que el modelo puede decidir ejecutar.
@tool
def get_text_length(text: str) -> int:
    ...
‚úÖ find_tool_by_name
Busca en la lista de herramientas (tools) la que coincida con el nombre que el modelo haya pedido usar.
def find_tool_by_name(tools, tool_name: str):
    ...
‚úÖ PromptTemplate
Define el formato ReAct que el modelo debe seguir.
Incluye los pasos de razonamiento (Thought), acci√≥n (Action / Action Input), observaci√≥n (Observation) y respuesta final (Final Answer).
template = """Answer the following questions ...
Thought: {agent_scratchpad}
"""
La variable {agent_scratchpad} se usa para insertar el historial de pasos intermedios (razonamientos previos y observaciones).
Esto le da al modelo ‚Äúmemoria‚Äù de lo que ya ha hecho.
‚úÖ ChatOpenAI
Es el modelo LLM que genera texto.
Se configura con un stop token para detener la generaci√≥n justo antes de ‚ÄúObservation‚Äù, de modo que el modelo no invente resultados de herramientas.
llm = ChatOpenAI(temperature=0, stop=["\nObservation:", "\n  Observation:", "Observation:"])
‚úÖ ReActSingleInputOutputParser
Interpreta la salida cruda del LLM (texto) y la convierte en una estructura de datos:
AgentAction si el modelo pide ejecutar una herramienta.
AgentFinish si ya dio su respuesta final.
üîÑ 3) Flujo completo del programa
Configuraci√≥n inicial
Carga variables de entorno (load_dotenv()).
Declara y registra la herramienta get_text_length.
Crea la lista tools = [get_text_length].
Define el PromptTemplate, el ChatOpenAI y el parser.
Primera invocaci√≥n del agente
Se llama al agente con la pregunta:
‚ÄúWhat is the length of the text: 'Hello, Leo!'?‚Äù
El modelo genera un texto como:
Thought: I need to find the length of the text.
Action: get_text_length
Action Input: "Hello, Leo!"
El parser convierte esa salida en un objeto AgentAction:
AgentAction(tool='get_text_length', tool_input='"Hello, Leo!"')
Ejecuci√≥n de la herramienta
Como el agente devuelve un AgentAction, el c√≥digo:
Busca la tool correspondiente (get_text_length).
Ejecuta su funci√≥n (tool_to_use.func(...)).
Obtiene una observaci√≥n real (por ejemplo, 12).
A√±ade (acci√≥n, observaci√≥n) a la lista intermediate_steps.
Esta lista act√∫a como memoria del agente y ser√° usada en la siguiente iteraci√≥n.
Segunda invocaci√≥n del agente
Se llama otra vez al agente, esta vez pasando intermediate_steps en el agent_scratchpad.
El prompt ahora incluye todo el razonamiento previo y la observaci√≥n real:
Thought: I need to find the length of the text.
Action: get_text_length
Action Input: "Hello, Leo!"
Observation: 12
Thought: I now know the final answer
Final Answer:
El modelo procesa esa informaci√≥n y produce un AgentFinish:
AgentFinish(return_values={"output": "12"})
Mostrar resultado final
Si el resultado es AgentFinish, el c√≥digo imprime el valor final:
Final Answer: {'output': '12'}
üß± 4) Estructuras que devuelve el parser
‚û§ AgentAction
Usado cuando el modelo elige una acci√≥n:
AgentAction(
  tool="get_text_length",
  tool_input='"Hello, Leo!"',
  log="Thought: ...\nAction: get_text_length\nAction Input: ..."
)
‚û§ AgentFinish
Usado cuando el modelo finaliza su respuesta:
AgentFinish(
  return_values={"output": "12"},
  log="Thought: I now know the final answer\nFinal Answer: 12"
)
üîç 5) Por qu√© el modelo no ejecuta la tool directamente
El modelo de lenguaje solo genera texto, no puede ejecutar c√≥digo Python ni funciones reales.
Por eso el flujo se divide as√≠:
El LLM decide qu√© hacer (razonamiento y elecci√≥n de herramienta).
El parser traduce su texto a una estructura comprensible para Python.
Tu c√≥digo ejecuta la herramienta real y devuelve la observaci√≥n.
El LLM usa esa observaci√≥n para completar su razonamiento y dar la respuesta final.
Esto mantiene seguridad y control, evitando que el modelo ejecute c√≥digo libremente.
üß† 6) En resumen
Etapa	Actor	Descripci√≥n
1. Razonamiento inicial	LLM	Decide qu√© herramienta usar
2. Parsing	LangChain	Convierte el texto en AgentAction
3. Ejecuci√≥n	Python	Ejecuta la tool real y obtiene una observaci√≥n
4. Segunda llamada	LLM	Usa la observaci√≥n para dar el Final Answer
5. Resultado final	Parser	Devuelve AgentFinish con la respuesta
üéØ 7) Resultado esperado
Al ejecutar el script, se ver√° algo como:
get_text_length received text: Hello, Leo!
Observation: 12
Intermediate Steps: [(AgentAction(...), 12)]
Second step: AgentFinish(return_values={'output': '12'})
Final Answer: {'output': '12'}
üí° 8) Qu√© se aprende con este c√≥digo
C√≥mo un agente ReAct razona paso a paso.
Qu√© hacen internamente AgentAction y AgentFinish.
C√≥mo se usan agent_scratchpad e intermediate_steps como memoria.
Por qu√© los LLM no ejecutan herramientas directamente.
C√≥mo construir manualmente el ciclo completo de pensamiento ‚Üí acci√≥n ‚Üí observaci√≥n ‚Üí respuesta.
üëâ En resumen, este c√≥digo ense√±a los fundamentos internos de los agentes LangChain, mostrando de manera pr√°ctica c√≥mo un modelo de lenguaje puede razonar, planificar acciones, ejecutarlas a trav√©s de Python, y llegar a conclusiones reales usando el patr√≥n ReAct.